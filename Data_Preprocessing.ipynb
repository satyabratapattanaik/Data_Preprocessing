{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee3de1b",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Data preprocessing is a key aspect of data preparation. It refers to any processing applied to raw data to ready it for further analysis or processing tasks. \n",
    "\n",
    "Traditionally, data preprocessing has been an essential preliminary step in data analysis. However, more recently, these techniques have been adapted to train machine learning and AI models and make inferences from them. \n",
    "\n",
    "Thus, data preprocessing may be defined as the process of converting raw data into a format that can be processed more efficiently and accurately in tasks such as: \n",
    "\n",
    "Data analysis\n",
    "Machine learning \n",
    "Data science\n",
    "AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f91a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b2a0b2",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Data cleaning is the process of identifying and correcting errors or inconsistencies in the data to ensure it is accurate and complete. The objective is to address issues that can distort analysis or model performance.\n",
    "\n",
    "For example: \n",
    "\n",
    "Handling missing values: Using strategies like mean/mode imputation, deletion, or predictive models to fill in or remove missing data.\n",
    "\n",
    "Removing duplicates: Eliminating duplicate records to ensure each entry is unique and relevant.\n",
    "\n",
    "Correcting inconsistent formats: Standardizing formats (e.g., date formats, string cases) to maintain consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ea3cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataset\n",
    "data = pd.DataFrame({\n",
    "    'name' : ['John', 'Jane', 'Jack', 'John', None],\n",
    "    'age' : [28, 34, None, 28, 22],\n",
    "    'purchase_amount' : [100.5, None, 85.3, 100.5, 50.0],\n",
    "    'date_of_purchase' : ['2023/12/01', '2023/12/02', '2023/12/01', '2023/12/01', '2023/12/03']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "625bd3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>date_of_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>100.5</td>\n",
       "      <td>2023/12/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023/12/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.3</td>\n",
       "      <td>2023/12/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>100.5</td>\n",
       "      <td>2023/12/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>22.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2023/12/03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name   age  purchase_amount date_of_purchase\n",
       "0  John  28.0            100.5       2023/12/01\n",
       "1  Jane  34.0              NaN       2023/12/02\n",
       "2  Jack   NaN             85.3       2023/12/01\n",
       "3  John  28.0            100.5       2023/12/01\n",
       "4  None  22.0             50.0       2023/12/03"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f92193db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values using mean imputation for 'age' and 'purchase_amount'\n",
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "data[['age', 'purchase_amount']] = imputer.fit_transform(data[['age', 'purchase_amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ac8e517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>date_of_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>100.500</td>\n",
       "      <td>2023/12/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>34.0</td>\n",
       "      <td>84.075</td>\n",
       "      <td>2023/12/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack</td>\n",
       "      <td>28.0</td>\n",
       "      <td>85.300</td>\n",
       "      <td>2023/12/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>100.500</td>\n",
       "      <td>2023/12/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>22.0</td>\n",
       "      <td>50.000</td>\n",
       "      <td>2023/12/03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name   age  purchase_amount date_of_purchase\n",
       "0  John  28.0          100.500       2023/12/01\n",
       "1  Jane  34.0           84.075       2023/12/02\n",
       "2  Jack  28.0           85.300       2023/12/01\n",
       "3  John  28.0          100.500       2023/12/01\n",
       "4  None  22.0           50.000       2023/12/03"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72838c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Duplicate row\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba015a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>date_of_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>100.500</td>\n",
       "      <td>2023/12/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>34.0</td>\n",
       "      <td>84.075</td>\n",
       "      <td>2023/12/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack</td>\n",
       "      <td>28.0</td>\n",
       "      <td>85.300</td>\n",
       "      <td>2023/12/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>22.0</td>\n",
       "      <td>50.000</td>\n",
       "      <td>2023/12/03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name   age  purchase_amount date_of_purchase\n",
       "0  John  28.0          100.500       2023/12/01\n",
       "1  Jane  34.0           84.075       2023/12/02\n",
       "2  Jack  28.0           85.300       2023/12/01\n",
       "4  None  22.0           50.000       2023/12/03"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d415761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting inconsistent date format\n",
    "data['date_of_purchase'] = pd.to_datetime(data['date_of_purchase'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34ca6404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>date_of_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>100.500</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>34.0</td>\n",
       "      <td>84.075</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack</td>\n",
       "      <td>28.0</td>\n",
       "      <td>85.300</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>22.0</td>\n",
       "      <td>50.000</td>\n",
       "      <td>2023-12-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name   age  purchase_amount date_of_purchase\n",
       "0  John  28.0          100.500       2023-12-01\n",
       "1  Jane  34.0           84.075       2023-12-02\n",
       "2  Jack  28.0           85.300       2023-12-01\n",
       "4  None  22.0           50.000       2023-12-03"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a0786e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>date_of_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>100.500</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>34.0</td>\n",
       "      <td>84.075</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack</td>\n",
       "      <td>28.0</td>\n",
       "      <td>85.300</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name   age  purchase_amount date_of_purchase\n",
       "0  John  28.0          100.500       2023-12-01\n",
       "1  Jane  34.0           84.075       2023-12-02\n",
       "2  Jack  28.0           85.300       2023-12-01"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962987f",
   "metadata": {},
   "source": [
    "# Data Integration\n",
    "\n",
    "Data integration involves combining data from multiple sources to create a unified dataset. This is often necessary when data is collected from different source systems.\n",
    "\n",
    "Some techniques used in data integration include: \n",
    "\n",
    "Schema matching: Aligning fields and data structures from different sources to ensure consistency.\n",
    "\n",
    "Data deduplication: Identifying and removing duplicate entries across multiple datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98175202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two manual datasets\n",
    "data1 = pd.DataFrame({\n",
    "    'customer_id' : [1, 2, 3],\n",
    "    'name' : ['John', 'Jane', 'Jack'],\n",
    "    'age' : [28, 34, 29]\n",
    "})\n",
    "\n",
    "data2 = pd.DataFrame({\n",
    "    'customer_id' : [1, 3, 4],\n",
    "    'purchase_amount' : [100.5, 85.3, 45.0],\n",
    "    'purchase_date' : ['2023-12-01', '2023-12-02', '2023-12-03']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd17e86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jack</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  name  age\n",
       "0            1  John   28\n",
       "1            2  Jane   34\n",
       "2            3  Jack   29"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7216e37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100.5</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>85.3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2023-12-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  purchase_amount purchase_date\n",
       "0            1            100.5    2023-12-01\n",
       "1            3             85.3    2023-12-02\n",
       "2            4             45.0    2023-12-03"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "941c4065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging datasets on a common key 'customer_id'\n",
    "merge_data = pd.merge(data1, data2, on='customer_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74f3795d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>28</td>\n",
       "      <td>100.5</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Jack</td>\n",
       "      <td>29</td>\n",
       "      <td>85.3</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  name  age  purchase_amount purchase_date\n",
       "0            1  John   28            100.5    2023-12-01\n",
       "1            3  Jack   29             85.3    2023-12-02"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f2deb3",
   "metadata": {},
   "source": [
    "# Data Transformation\n",
    "\n",
    "Data transformation converts data into formats suitable for analysis, machine learning, or mining. \n",
    "\n",
    "For example: \n",
    "\n",
    "Scaling and normalization: Adjusting numeric values to a common scale is often necessary for algorithms that rely on distance metrics.\n",
    "\n",
    "Encoding categorical variables: Converting categorical data into numerical values using one-hot or label encoding techniques.\n",
    "\n",
    "Feature engineering and extraction: Creating new features or selecting important ones to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6337d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2194eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset\n",
    "data3 = pd.DataFrame({\n",
    "    'category' : ['A', 'B', 'A', 'C', 'B'],\n",
    "    'numeric_column' : [10, 15, 10, 20, 15]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19ecaf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category  numeric_column\n",
      "0        A              10\n",
      "1        B              15\n",
      "2        A              10\n",
      "3        C              20\n",
      "4        B              15\n"
     ]
    }
   ],
   "source": [
    "print(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "872106af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numeric data\n",
    "scaler = StandardScaler()\n",
    "data3['scaled_numeric_column'] = scaler.fit_transform(data3[['numeric_column']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76a06f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category  numeric_column  scaled_numeric_column\n",
      "0        A              10              -1.069045\n",
      "1        B              15               0.267261\n",
      "2        A              10              -1.069045\n",
      "3        C              20               1.603567\n",
      "4        B              15               0.267261\n"
     ]
    }
   ],
   "source": [
    "print(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8062d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical value\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_data = pd.DataFrame(encoder.fit_transform(data3[['category']]), columns=encoder.get_feature_names_out(['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcd93a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category_A  category_B  category_C\n",
      "0         1.0         0.0         0.0\n",
      "1         0.0         1.0         0.0\n",
      "2         1.0         0.0         0.0\n",
      "3         0.0         0.0         1.0\n",
      "4         0.0         1.0         0.0\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27c5a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the encoded data with the original dataset\n",
    "data3 = pd.concat([data3, encoded_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e5b14ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category  numeric_column  scaled_numeric_column  category_A  category_B  \\\n",
      "0        A            10.0              -1.069045         NaN         NaN   \n",
      "1        B            15.0               0.267261         NaN         NaN   \n",
      "2        A            10.0              -1.069045         NaN         NaN   \n",
      "3        C            20.0               1.603567         NaN         NaN   \n",
      "4        B            15.0               0.267261         NaN         NaN   \n",
      "0      NaN             NaN                    NaN         1.0         0.0   \n",
      "1      NaN             NaN                    NaN         0.0         1.0   \n",
      "2      NaN             NaN                    NaN         1.0         0.0   \n",
      "3      NaN             NaN                    NaN         0.0         0.0   \n",
      "4      NaN             NaN                    NaN         0.0         1.0   \n",
      "\n",
      "   category_C  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         1.0  \n",
      "4         0.0  \n"
     ]
    }
   ],
   "source": [
    "print(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee46a36",
   "metadata": {},
   "source": [
    "# Data Reduction\n",
    "\n",
    "Data reduction simplifies the dataset by reducing the number of features or records while preserving the essential information. This helps speed up analysis and model training without sacrificing accuracy.\n",
    "\n",
    "Techniques for data reduction include: \n",
    "\n",
    "Feature selection: Choosing the most important features contributing to the analysis or model's performance.\n",
    "\n",
    "Principal component analysis (PCA): A dimensionality reduction technique that transforms data into a lower-dimensional space.\n",
    "\n",
    "Sampling methods: Reducing the size of the dataset by selecting representative samples is useful for handling large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ed454a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d36ce65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2  feature3  target\n",
      "0        10         1       100       0\n",
      "1        20         2       200       1\n",
      "2        30         3       300       0\n",
      "3        40         4       400       1\n",
      "4        50         5       500       0\n"
     ]
    }
   ],
   "source": [
    "# Creating Dataset\n",
    "data4 = pd.DataFrame({\n",
    "    'feature1' : [10, 20, 30, 40, 50],\n",
    "    'feature2' : [1, 2, 3, 4, 5],\n",
    "    'feature3' : [100, 200, 300, 400, 500],\n",
    "    'target' : [0, 1, 0, 1, 0]\n",
    "})\n",
    "\n",
    "print(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5c227a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1 100]\n",
      " [  2 200]\n",
      " [  3 300]\n",
      " [  4 400]\n",
      " [  5 500]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection using SelectkBest\n",
    "selector = SelectKBest(chi2, k=2)\n",
    "selected_features = selector.fit_transform(data4[['feature1', 'feature2', 'feature3']], data4['target'])\n",
    "\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86b317df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.01007463e+02 -2.69618663e-15]\n",
      " [-1.00503731e+02  8.98728878e-16]\n",
      " [ 0.00000000e+00 -0.00000000e+00]\n",
      " [ 1.00503731e+02 -8.98728878e-16]\n",
      " [ 2.01007463e+02 -1.79745776e-15]]\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality reduction using PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(data4[['feature1', 'feature2', 'feature3']])\n",
    "\n",
    "print(pca_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c3eb2",
   "metadata": {},
   "source": [
    "# Handling missing data\n",
    "\n",
    "Missing data can negatively impact the performance of a machine learning model or analysis. There are several strategies to handle missing values effectively:\n",
    "\n",
    "Imputation: This technique involves filling in missing values with a calculated estimate, such as the mean, median, or mode of the available data. Advanced methods include predictive modeling, where missing values are predicted based on relationships within the data.\n",
    "\n",
    "Deletion: Removing rows or columns with missing values is a straightforward solution. However, it should be used cautiously as it can lead to loss of valuable data, especially if many entries are missing.\n",
    "\n",
    "Modeling missing values: In cases where the missing data pattern is more complex, machine learning models can predict the missing values based on the rest of the dataset. This can improve accuracy by incorporating relationships between different variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408acd53",
   "metadata": {},
   "source": [
    "# Outlier detection and removal\n",
    "\n",
    "Outliers are extreme values that deviate significantly from the rest of the data, which, like missing values, can distort analysis and model performance. Various techniques can be used to detect and handle outliers:\n",
    "\n",
    "Z-Score method: This approach measures how many standard deviations a data point is from the mean. Data points beyond a certain threshold (e.g., ±3 standard deviations) can be considered outliers.\n",
    "\n",
    "Interquartile range (IQR): IQR is the range between the first quartile (Q1) and the third quartile (Q3). Values beyond 1.5 times the IQR above Q3 or below Q1 are considered outliers.\n",
    "\n",
    "Visual techniques: Visualization methods like box plots, scatter plots, or histograms can help detect outliers in a dataset. Once identified, outliers can either be removed or transformed, depending on their influence on the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6695d9f",
   "metadata": {},
   "source": [
    "# Data encoding\n",
    "\n",
    "When working with categorical data, encoding is necessary to convert categories into numerical representations that machine learning algorithms can process. Common encoding techniques include:\n",
    "\n",
    "One-hot encoding: As mentioned before, this method creates binary columns [0, 1] for each category.\n",
    "\n",
    "Label encoding: Label encoding assigns a unique numerical value to each category. However, this method can introduce an unintended ordinal relationship between categories if they don’t have a natural order.\n",
    "\n",
    "Ordinal encoding: Ordinal encoding is used when categorical variables have an inherent order, like low, medium, and high. Each category is mapped to a corresponding integer value that reflects its ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c142823",
   "metadata": {},
   "source": [
    "# Data scaling and normalization\n",
    "\n",
    "Scaling and normalization ensure that numerical features are on a similar scale, which is particularly important for algorithms that rely on distance metrics (e.g., k-nearest neighbors, SVMs).\n",
    "\n",
    "Min-max scaling: This technique scales data to a specified range, typically 0 to 1. It's useful when all features need to have the same scale.\n",
    "\n",
    "Standardization (Z-Score normalization): This method scales data such that the mean becomes 0 and the standard deviation becomes 1, helping models perform better with normally distributed features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a22286",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "Data augmentation is a technique for artificially increasing the size of a dataset by creating new, synthetic examples. This is especially useful for image or text datasets in deep learning models, where large amounts of data are required for robust model performance.\n",
    "\n",
    "Image augmentation: Techniques like rotating, flipping, scaling, or adding noise to images help create variations that improve model generalization.\n",
    "\n",
    "Text augmentation: For text data, augmentation methods include synonym replacement, random insertion, and back-translation, where a sentence is translated into another language and then back into the original language, introducing variations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3adc73",
   "metadata": {},
   "source": [
    "# Tools for Data Preprocessing\n",
    "\n",
    "While you can implement data processing using pure Python code, powerful tools have been developed to handle various tasks and make the overall process more efficient. Here are a few examples: \n",
    "\n",
    "1. Python libraries\n",
    "\n",
    "There are quite a few specialized libraries for data preprocessing in Python. Here are 3 of the most popular: \n",
    "\n",
    "Pandas: Python's most commonly used library for data manipulation and cleaning. It provides flexible data structures, primarily DataFrame and Series, which enable you to handle and manipulate structured data efficiently. Pandas supports operations like handling missing data, merging datasets, filtering data, and reshaping.\n",
    "\n",
    "NumPy: A fundamental library for numerical computations. It supports large, multi-dimensional arrays and matrices and mathematical functions to operate on these arrays. NumPy is often the foundation for many higher-level data processing libraries, such as Pandas.\n",
    "\n",
    "Scikit-learn: Widely used for machine learning tasks but also offers numerous preprocessing utilities, such as scaling, encoding, and data transformation. Its preprocessing module contains tools for handling categorical data, scaling numerical data, feature extraction, and more.\n",
    "\n",
    "2. Cloud platforms\n",
    "\n",
    "On-premise systems may not be able to handle large datasets effectively. In such situations, cloud platforms offer scalable, efficient solutions that enable you to process vast amounts of data across distributed systems. \n",
    "\n",
    "Some cloud platform tools to consider include: \n",
    "\n",
    "AWS Glue: A fully managed ETL service by Amazon Web Services. It automatically discovers and organizes data and prepares it for analytics. Glue supports data cataloging and can connect to AWS services like S3 and Redshift.\n",
    "\n",
    "Azure Data Factory: A cloud-based data integration service from Microsoft. It supports building ETL and ELT pipelines for large-scale data. Azure Data Factory allows users to move data between various services, preprocess it using transformations, and orchestrate workflows using a visual interface."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
